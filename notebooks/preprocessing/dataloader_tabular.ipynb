{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Dataloader for contrastive learning with tabular data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from abc import ABC\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "paths = config.Paths()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Pytorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class TabularDataset(Dataset, ABC):\n",
    "    \"\"\"Tabular Dataset for contrastive learning using a VAE model\"\"\"\n",
    "\n",
    "    def __init__(self, df = None, label_col = 'label'):\n",
    "        self.label_col = label_col\n",
    "\n",
    "        super(TabularDataset, self).__init__()\n",
    "        if df is None:\n",
    "            self.__get_data()\n",
    "        else:\n",
    "            self.data = df\n",
    "\n",
    "        self.inputs = np.array(self.data.drop(columns=[self.label_col]))\n",
    "        self.labels = np.array(self.data[self.label_col])\n",
    "\n",
    "        if type(self.labels[0]) == str:\n",
    "            self.__encode_labels()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input1 = torch.from_numpy(self.inputs[idx]).float()\n",
    "        label = torch.from_numpy(np.array(self.labels[idx])).long()\n",
    "\n",
    "        return input1, label\n",
    "\n",
    "    def __get_data(self):\n",
    "        df = pd.read_csv('../../../' + paths.data_dir + 'raw/paldat_complete_clean.csv')\n",
    "\n",
    "        # drop non numerical columns except for label\n",
    "        labels = df[self.label_col]\n",
    "        df = df._get_numeric_data()\n",
    "        df[self.label_col] = labels\n",
    "\n",
    "        #normalize columns\n",
    "        for col in df.columns:\n",
    "            if col != self.label_col:\n",
    "                df[col] = (df[col] - df[col].min()) / (df[col].max() - df[col].min())\n",
    "\n",
    "        # drop columns with nan values\n",
    "        df = df.dropna(axis=1)\n",
    "        self.data = df\n",
    "\n",
    "    def __encode_labels(self):\n",
    "        le = LabelEncoder()\n",
    "        self.labels = le.fit_transform(self.labels)\n",
    "        self.label_names = le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset = TabularDataset(label_col = 'family')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset.__getitem__(0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cols = dataset.data.columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_one_hot_index(cols):\n",
    "    \"\"\"\n",
    "    generates a list of indexes (start, end) for one hot encoded columns based on prefix of column names\n",
    "    :param cols: list of column names\n",
    "    :return: list of (start, end) tuples\n",
    "    \"\"\"\n",
    "    one_hot_index = []\n",
    "    start = 0\n",
    "    end = 0\n",
    "    current = cols[0].split('_')[0]\n",
    "    for i in cols:\n",
    "        if i.split('_')[0] == current:\n",
    "            end += 1\n",
    "        else:\n",
    "            one_hot_index.append((start, end))\n",
    "            start = end\n",
    "            end += 1\n",
    "            current = i.split('_')[0]\n",
    "\n",
    "    return one_hot_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "get_one_hot_index(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Triplet Loss Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class TripletDataset(Dataset, ABC):\n",
    "    \"\"\"Tabular Dataset generating triplets for contrastive learning using a VAE model\"\"\"\n",
    "\n",
    "    def __init__(self, df = None, label_col = 'label', setting='train'):\n",
    "        \"\"\"\n",
    "        Initializes the dataset. If no dataframe is given, the data is loaded from the csv file\n",
    "        and normalized. If a dataframe is given, it is assumed that the data is already normalized\n",
    "        :param df: dataframe containing data\n",
    "        :param label_col: name of the column containing the labels\n",
    "        :param setting: 'train' or 'test'\n",
    "        \"\"\"\n",
    "        self.label_col = label_col\n",
    "\n",
    "        super(TripletDataset, self).__init__()\n",
    "        if df is None:\n",
    "            self.__get_data(setting=setting)\n",
    "        else:\n",
    "            self.data = df\n",
    "\n",
    "        self.inputs = np.array(self.data.drop(columns=[self.label_col]))\n",
    "        self.labels = np.array(self.data[self.label_col])\n",
    "\n",
    "        if type(self.labels[0]) == str:\n",
    "            self.__encode_labels()\n",
    "\n",
    "        self.one_hot_index = get_one_hot_index(self.data.columns)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Returns a triplet of data points and their labels\n",
    "        :param idx: index of anchor point\n",
    "        :return: anchor, postive, negative, labels\n",
    "        \"\"\"\n",
    "        anchor_idx, postive_idx, negative_idx =  self.__get_triplet(idx)\n",
    "\n",
    "        anchor = torch.from_numpy(self.inputs[anchor_idx]).float()\n",
    "        postive = torch.from_numpy(self.inputs[postive_idx]).float()\n",
    "        negative = torch.from_numpy(self.inputs[negative_idx]).float()\n",
    "\n",
    "        labels = {'anchor': torch.from_numpy(np.array(self.labels[anchor_idx])).long(),\n",
    "                  'positive': torch.from_numpy(np.array(self.labels[postive_idx])).long(),\n",
    "                  'negative': torch.from_numpy(np.array(self.labels[negative_idx])).long()}\n",
    "\n",
    "        return anchor, postive, negative, labels\n",
    "\n",
    "    def __get_data(self, setting:str ='train'):\n",
    "        \"\"\"\n",
    "        Loads data from csv file and normalizes it. According to setting, only train or test data is loaded\n",
    "        :param setting: 'train' or 'test'\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        df = pd.read_csv('../../../' + paths.data_dir + 'raw/paldat_complete_clean.csv')\n",
    "\n",
    "        if setting == 'train':\n",
    "            df = df[df['setting'] == 'train']\n",
    "        elif setting == 'test':\n",
    "            df = df[df['setting'] == 'test']\n",
    "\n",
    "        df.drop(columns=['setting'], inplace=True)\n",
    "\n",
    "        # drop non numerical columns except for label\n",
    "        labels = df[self.label_col]\n",
    "        df = df._get_numeric_data() # naughty\n",
    "        df[self.label_col] = labels\n",
    "\n",
    "        #normalize columns\n",
    "        for col in df.columns:\n",
    "            if col != self.label_col:\n",
    "                df[col] = (df[col] - df[col].min()) / (df[col].max() - df[col].min())\n",
    "\n",
    "        # drop columns with nan values\n",
    "        df = df.dropna(axis=1)\n",
    "        self.data = df\n",
    "\n",
    "    def __encode_labels(self):\n",
    "        \"\"\"\n",
    "        Encodes labels to integers. Saves label names in self.label_names\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        le = LabelEncoder()\n",
    "        self.labels = le.fit_transform(self.labels)\n",
    "        self.label_names = le.classes_\n",
    "\n",
    "    def __get_triplet(self, idx):\n",
    "        \"\"\"\n",
    "        Generates a triplet based on target column self.label_col\n",
    "        :return: triplet\n",
    "        \"\"\"\n",
    "        # get gLabel\n",
    "        label = self.data.iloc[idx][self.label_col]\n",
    "\n",
    "        # get anchor and positive from label\n",
    "        anchor_idx = np.random.choice(self.data[self.data[self.label_col] == label].index)\n",
    "        positive_idx = np.random.choice(self.data[self.data[self.label_col] == label].index)\n",
    "\n",
    "        # get negative from different label\n",
    "        negative_label = random.choice(self.label_names)\n",
    "        while negative_label == label:\n",
    "            negative_label = random.choice(self.label_names)\n",
    "\n",
    "        negative_idx = np.random.choice(self.data[self.data[self.label_col] == negative_label].index)\n",
    "\n",
    "        return anchor_idx, positive_idx, negative_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset = TripletDataset(label_col = 'family')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True, drop_last=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}